{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New Project File:\n",
    "\n",
    "Shell for the CAPTCHA Cracking Challenge\n",
    "\n",
    "There are 8501 training images and a secret number of test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['5637', 'eszpbp', 'jpeg']\n",
      "ESZPBP\n",
      "5637.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import patches as ptc \n",
    "import math\n",
    "import random\n",
    "from PIL import Image\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Define function for converting text to one-hot numerical encoding\n",
    "\n",
    "def OneHotConverter(textstring, dictionary): # Needs to be a reverse dictionary\n",
    "\n",
    "    ans = np.zeros((6, 21))\n",
    "    for i in range(6):\n",
    "        char = textstring[i].upper()\n",
    "        num = dictionary[char]#dict2\n",
    "        ans[i][num] = 1\n",
    "    return ans \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "# Define dictionaries for encoding/decoding\n",
    "dict1 = {0:'2', 1:'6', 2:'A', 3:'B', 4:'C', 5:'D', 6:'E', 7:'F', 8:'G', 9:'H', 10:'K', 11:'M', \n",
    "              12:'N', 13:'P', 14:'R', 15:'S', 16:'T', 17:'U', 18:'V', 19:'X', 20:'Z'}\n",
    "dict2 = {v: k for k, v in dict1.items()}\n",
    "\n",
    "\n",
    "\n",
    "trainfiles2 = os.listdir('./traindata/')\n",
    "trainfiles = [f for f in trainfiles2 if os.path.isfile('.' +'/traindata/' + f)] #Filtering only the files.\n",
    "valfiles2 = os.listdir('./valdata/')\n",
    "valfiles = [f for f in valfiles2 if os.path.isfile('.' +'/valdata/' + f)]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "random.shuffle(trainfiles)\n",
    "numtrain = len(trainfiles)\n",
    "numval = len(valfiles)\n",
    "\n",
    "train_images = np.zeros((numtrain,250,50))\n",
    "train_labels = np.zeros((numtrain,6,21))\n",
    "train_labels1 = np.zeros((numtrain, 21))\n",
    "train_labels2 = np.zeros((numtrain, 21))\n",
    "train_labels3 = np.zeros((numtrain, 21))\n",
    "train_labels4 = np.zeros((numtrain, 21))\n",
    "train_labels5 = np.zeros((numtrain, 21))\n",
    "train_labels6 = np.zeros((numtrain, 21))\n",
    "train_numlist = np.zeros((numtrain))\n",
    "train_letters = ['     '] * numtrain\n",
    "\n",
    "val_images = np.zeros((numval,250,50))\n",
    "val_labels = np.zeros((numval,6,21))\n",
    "val_labels1 = np.zeros((numval, 21))\n",
    "val_labels2 = np.zeros((numval, 21))\n",
    "val_labels3 = np.zeros((numval, 21))\n",
    "val_labels4 = np.zeros((numval, 21))\n",
    "val_labels5 = np.zeros((numval, 21))\n",
    "val_labels6 = np.zeros((numval, 21))\n",
    "val_numlist = np.zeros((numval))\n",
    "val_letters = ['     '] * numval\n",
    "\n",
    "\n",
    "# Define training set\n",
    "for i in range(numtrain):\n",
    "    img = Image.open('./traindata/' + trainfiles[i]).convert('L')\n",
    "    data = np.transpose(np.asarray(img)) / 255\n",
    "    train_images[i] = data\n",
    "    train_numlist[i] = re.split(r\"[_.]\", trainfiles[i])[0]\n",
    "    temp = re.split(r\"[_.]\", trainfiles[i])\n",
    "    train_labels[i] = OneHotConverter(temp[1], dict2)\n",
    "    train_labels1[i] = train_labels[i][0]\n",
    "    train_labels2[i] = train_labels[i][1]\n",
    "    train_labels3[i] = train_labels[i][2]\n",
    "    train_labels4[i] = train_labels[i][3]\n",
    "    train_labels5[i] = train_labels[i][4]\n",
    "    train_labels6[i] = train_labels[i][5]\n",
    "    train_letters[i] = temp[1].upper()\n",
    "\n",
    "# Define validation set\n",
    "for i in range(numval):\n",
    "    img = Image.open('./valdata/' + valfiles[i]).convert('L')\n",
    "    data = np.transpose(np.asarray(img)) / 255\n",
    "    val_images[i] = data\n",
    "    val_numlist[i] = re.split(r\"[_.]\", valfiles[i])[0]\n",
    "    temp = re.split(r\"[_.]\", valfiles[i])\n",
    "    val_labels[i] = OneHotConverter(temp[1], dict2)\n",
    "    val_labels1[i] = val_labels[i][0]\n",
    "    val_labels2[i] = val_labels[i][1]\n",
    "    val_labels3[i] = val_labels[i][2]\n",
    "    val_labels4[i] = val_labels[i][3]\n",
    "    val_labels5[i] = val_labels[i][4]\n",
    "    val_labels6[i] = val_labels[i][5]\n",
    "    val_letters[i] = temp[1].upper()\n",
    "\n",
    "\n",
    "\n",
    "# Note to self: add validation and test sets, comment out test set construction since the students\n",
    "# Won't get the test set until the final\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Below is an example of how you can get the info from a train or validation file\n",
    "print(re.split(r\"[_.]\", trainfiles[0]))\n",
    "\n",
    "print(train_letters[0])\n",
    "print(train_numlist[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the model.  \n",
    "\n",
    "Input layer: 250x50 pixel images in grayscale (0 to 1 values)\n",
    "\n",
    "ADD NETWORK HERE\n",
    "\n",
    "\n",
    "Final activation function needs to be softmax\n",
    "Output: 6*21 matrix, each of the 6 21 entry rows is a confidence vector for the given character\n",
    "Loss functions: 6 copies of cross-entropy for the 6 different characters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " Input (InputLayer)             [(None, 250, 50, 1)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " Convolution (Conv2D)           (None, 250, 50, 30)  510         ['Input[0][0]']                  \n",
      "                                                                                                  \n",
      " MaxPool1 (MaxPooling2D)        (None, 124, 24, 30)  0           ['Convolution[0][0]']            \n",
      "                                                                                                  \n",
      " Convolution2 (Conv2D)          (None, 124, 24, 20)  9620        ['MaxPool1[0][0]']               \n",
      "                                                                                                  \n",
      " MaxPool2 (MaxPooling2D)        (None, 121, 21, 20)  0           ['Convolution2[0][0]']           \n",
      "                                                                                                  \n",
      " Dropout1 (Dropout)             (None, 121, 21, 20)  0           ['MaxPool2[0][0]']               \n",
      "                                                                                                  \n",
      " Convolution3 (Conv2D)          (None, 121, 21, 10)  3210        ['Dropout1[0][0]']               \n",
      "                                                                                                  \n",
      " MaxPool3 (MaxPooling2D)        (None, 119, 19, 10)  0           ['Convolution3[0][0]']           \n",
      "                                                                                                  \n",
      " Flatten (Flatten)              (None, 22610)        0           ['MaxPool3[0][0]']               \n",
      "                                                                                                  \n",
      " Char_1 (Dense)                 (None, 21)           474831      ['Flatten[0][0]']                \n",
      "                                                                                                  \n",
      " Char_2 (Dense)                 (None, 21)           474831      ['Flatten[0][0]']                \n",
      "                                                                                                  \n",
      " Char_3 (Dense)                 (None, 21)           474831      ['Flatten[0][0]']                \n",
      "                                                                                                  \n",
      " Char_4 (Dense)                 (None, 21)           474831      ['Flatten[0][0]']                \n",
      "                                                                                                  \n",
      " Char_5 (Dense)                 (None, 21)           474831      ['Flatten[0][0]']                \n",
      "                                                                                                  \n",
      " Char_6 (Dense)                 (None, 21)           474831      ['Flatten[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,862,326\n",
      "Trainable params: 2,862,326\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "inputlayer = tf.keras.Input(shape=(250, 50, 1), name=\"Input\")\n",
    "\n",
    "\n",
    "# Right now the network is basically the same as our example McDigit one\n",
    "# You'll need to add/change a lot between here and the dense layers at the end\n",
    "convlayer1 = tf.keras.layers.Conv2D(filters=30, kernel_size=(4,4),padding='same', name=\"Convolution\")(inputlayer)\n",
    "maxpoollayer1 = tf.keras.layers.MaxPooling2D(pool_size=(4,4),strides=(2,2), name=\"MaxPool1\")(convlayer1)\n",
    "\n",
    "\n",
    "convlayer2 = tf.keras.layers.Conv2D(filters=20, kernel_size=(4,4),padding='same', name=\"Convolution2\")(maxpoollayer1)\n",
    "maxpoollayer2 = tf.keras.layers.MaxPooling2D(pool_size=(4,4),strides=(1,1), name=\"MaxPool2\")(convlayer2)\n",
    "dropout_layer1 = tf.keras.layers.Dropout(rate=0.25,name=\"Dropout1\")(maxpoollayer2)\n",
    "\n",
    "convlayer3 = tf.keras.layers.Conv2D(filters=10, kernel_size=(4,4),padding='same', name=\"Convolution3\")(dropout_layer1)\n",
    "maxpoollayer3 = tf.keras.layers.MaxPooling2D(pool_size=(3,3),strides=(1,1), name=\"MaxPool3\")(convlayer3)\n",
    "\n",
    "flatlayer = tf.keras.layers.Flatten(name=\"Flatten\")(maxpoollayer3)\n",
    "\n",
    "# denselayer1 = tf.keras.layers.Dense(40, activation='relu', name='Dense')(flatlayer)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "char1 = tf.keras.layers.Dense(21, activation='softmax', name='Char_1')(flatlayer)\n",
    "char2 = tf.keras.layers.Dense(21, activation='softmax', name='Char_2')(flatlayer)\n",
    "char3 = tf.keras.layers.Dense(21, activation='softmax', name='Char_3')(flatlayer)\n",
    "char4 = tf.keras.layers.Dense(21, activation='softmax', name='Char_4')(flatlayer)\n",
    "char5 = tf.keras.layers.Dense(21, activation='softmax', name='Char_5')(flatlayer)\n",
    "char6 = tf.keras.layers.Dense(21, activation='softmax', name='Char_6')(flatlayer)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputlayer, outputs=[char1, char2, char3, char4, char5, char6])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "  loss={\n",
    "      \"Char_1\": tf.keras.losses.CategoricalCrossentropy(),\n",
    "      \"Char_2\": tf.keras.losses.CategoricalCrossentropy(),\n",
    "      \"Char_3\": tf.keras.losses.CategoricalCrossentropy(),\n",
    "      \"Char_4\": tf.keras.losses.CategoricalCrossentropy(),\n",
    "      \"Char_5\": tf.keras.losses.CategoricalCrossentropy(),\n",
    "      \"Char_6\": tf.keras.losses.CategoricalCrossentropy()\n",
    "      },\n",
    "  metrics=['accuracy']\n",
    "  )\n",
    "\n",
    "tf.keras.utils.plot_model(model, \"model.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "67/67 [==============================] - 36s 529ms/step - loss: 16.8818 - Char_1_loss: 2.7504 - Char_2_loss: 2.8399 - Char_3_loss: 2.8158 - Char_4_loss: 2.8680 - Char_5_loss: 2.8324 - Char_6_loss: 2.7753 - Char_1_accuracy: 0.1934 - Char_2_accuracy: 0.1601 - Char_3_accuracy: 0.1733 - Char_4_accuracy: 0.1595 - Char_5_accuracy: 0.1583 - Char_6_accuracy: 0.1832 - val_loss: 18.2088 - val_Char_1_loss: 2.8384 - val_Char_2_loss: 3.9424 - val_Char_3_loss: 2.7326 - val_Char_4_loss: 3.1355 - val_Char_5_loss: 2.8462 - val_Char_6_loss: 2.7136 - val_Char_1_accuracy: 0.2160 - val_Char_2_accuracy: 0.1320 - val_Char_3_accuracy: 0.2580 - val_Char_4_accuracy: 0.1820 - val_Char_5_accuracy: 0.1900 - val_Char_6_accuracy: 0.2900\n",
      "Epoch 2/50\n",
      "67/67 [==============================] - 37s 558ms/step - loss: 7.6933 - Char_1_loss: 1.1134 - Char_2_loss: 1.3567 - Char_3_loss: 1.3457 - Char_4_loss: 1.3964 - Char_5_loss: 1.3922 - Char_6_loss: 1.0890 - Char_1_accuracy: 0.6607 - Char_2_accuracy: 0.5802 - Char_3_accuracy: 0.5905 - Char_4_accuracy: 0.5683 - Char_5_accuracy: 0.5775 - Char_6_accuracy: 0.6826 - val_loss: 7.4186 - val_Char_1_loss: 1.1073 - val_Char_2_loss: 1.6976 - val_Char_3_loss: 1.2012 - val_Char_4_loss: 1.2396 - val_Char_5_loss: 1.2400 - val_Char_6_loss: 0.9328 - val_Char_1_accuracy: 0.6260 - val_Char_2_accuracy: 0.5080 - val_Char_3_accuracy: 0.6220 - val_Char_4_accuracy: 0.6420 - val_Char_5_accuracy: 0.6060 - val_Char_6_accuracy: 0.7160\n",
      "Epoch 3/50\n",
      "67/67 [==============================] - 37s 550ms/step - loss: 3.4450 - Char_1_loss: 0.4256 - Char_2_loss: 0.6552 - Char_3_loss: 0.6344 - Char_4_loss: 0.6749 - Char_5_loss: 0.6657 - Char_6_loss: 0.3891 - Char_1_accuracy: 0.8732 - Char_2_accuracy: 0.7913 - Char_3_accuracy: 0.8060 - Char_4_accuracy: 0.7947 - Char_5_accuracy: 0.7967 - Char_6_accuracy: 0.8891 - val_loss: 5.1590 - val_Char_1_loss: 0.7457 - val_Char_2_loss: 1.0823 - val_Char_3_loss: 0.9669 - val_Char_4_loss: 0.8695 - val_Char_5_loss: 0.8910 - val_Char_6_loss: 0.6036 - val_Char_1_accuracy: 0.7320 - val_Char_2_accuracy: 0.6560 - val_Char_3_accuracy: 0.6840 - val_Char_4_accuracy: 0.7340 - val_Char_5_accuracy: 0.7060 - val_Char_6_accuracy: 0.8300\n",
      "Epoch 4/50\n",
      "67/67 [==============================] - 38s 566ms/step - loss: 2.0089 - Char_1_loss: 0.2232 - Char_2_loss: 0.3856 - Char_3_loss: 0.3702 - Char_4_loss: 0.4149 - Char_5_loss: 0.4260 - Char_6_loss: 0.1891 - Char_1_accuracy: 0.9373 - Char_2_accuracy: 0.8851 - Char_3_accuracy: 0.8877 - Char_4_accuracy: 0.8725 - Char_5_accuracy: 0.8745 - Char_6_accuracy: 0.9478 - val_loss: 4.5162 - val_Char_1_loss: 0.5197 - val_Char_2_loss: 0.8997 - val_Char_3_loss: 0.9106 - val_Char_4_loss: 0.8232 - val_Char_5_loss: 0.8066 - val_Char_6_loss: 0.5564 - val_Char_1_accuracy: 0.8420 - val_Char_2_accuracy: 0.7320 - val_Char_3_accuracy: 0.7200 - val_Char_4_accuracy: 0.7460 - val_Char_5_accuracy: 0.7580 - val_Char_6_accuracy: 0.8240\n",
      "Epoch 5/50\n",
      "67/67 [==============================] - 41s 604ms/step - loss: 1.3134 - Char_1_loss: 0.1415 - Char_2_loss: 0.2471 - Char_3_loss: 0.2542 - Char_4_loss: 0.2842 - Char_5_loss: 0.2835 - Char_6_loss: 0.1029 - Char_1_accuracy: 0.9587 - Char_2_accuracy: 0.9254 - Char_3_accuracy: 0.9225 - Char_4_accuracy: 0.9131 - Char_5_accuracy: 0.9104 - Char_6_accuracy: 0.9727 - val_loss: 4.3649 - val_Char_1_loss: 0.4701 - val_Char_2_loss: 0.9344 - val_Char_3_loss: 0.8578 - val_Char_4_loss: 0.7367 - val_Char_5_loss: 0.8049 - val_Char_6_loss: 0.5610 - val_Char_1_accuracy: 0.8460 - val_Char_2_accuracy: 0.7380 - val_Char_3_accuracy: 0.7920 - val_Char_4_accuracy: 0.7960 - val_Char_5_accuracy: 0.7780 - val_Char_6_accuracy: 0.8460\n",
      "Epoch 6/50\n",
      "67/67 [==============================] - 33s 496ms/step - loss: 0.8915 - Char_1_loss: 0.0865 - Char_2_loss: 0.1655 - Char_3_loss: 0.1805 - Char_4_loss: 0.2058 - Char_5_loss: 0.1922 - Char_6_loss: 0.0610 - Char_1_accuracy: 0.9745 - Char_2_accuracy: 0.9465 - Char_3_accuracy: 0.9444 - Char_4_accuracy: 0.9358 - Char_5_accuracy: 0.9407 - Char_6_accuracy: 0.9852 - val_loss: 3.7709 - val_Char_1_loss: 0.4956 - val_Char_2_loss: 0.7193 - val_Char_3_loss: 0.7658 - val_Char_4_loss: 0.6736 - val_Char_5_loss: 0.6938 - val_Char_6_loss: 0.4227 - val_Char_1_accuracy: 0.8460 - val_Char_2_accuracy: 0.8080 - val_Char_3_accuracy: 0.7960 - val_Char_4_accuracy: 0.8060 - val_Char_5_accuracy: 0.8200 - val_Char_6_accuracy: 0.8960\n",
      "Epoch 7/50\n",
      "67/67 [==============================] - 34s 501ms/step - loss: 0.6197 - Char_1_loss: 0.0594 - Char_2_loss: 0.1151 - Char_3_loss: 0.1197 - Char_4_loss: 0.1366 - Char_5_loss: 0.1450 - Char_6_loss: 0.0439 - Char_1_accuracy: 0.9835 - Char_2_accuracy: 0.9639 - Char_3_accuracy: 0.9627 - Char_4_accuracy: 0.9577 - Char_5_accuracy: 0.9540 - Char_6_accuracy: 0.9904 - val_loss: 3.6140 - val_Char_1_loss: 0.3569 - val_Char_2_loss: 0.7627 - val_Char_3_loss: 0.8137 - val_Char_4_loss: 0.6198 - val_Char_5_loss: 0.6815 - val_Char_6_loss: 0.3794 - val_Char_1_accuracy: 0.8960 - val_Char_2_accuracy: 0.8200 - val_Char_3_accuracy: 0.7860 - val_Char_4_accuracy: 0.8420 - val_Char_5_accuracy: 0.8160 - val_Char_6_accuracy: 0.9020\n",
      "Epoch 8/50\n",
      "67/67 [==============================] - 34s 506ms/step - loss: 0.4908 - Char_1_loss: 0.0475 - Char_2_loss: 0.0849 - Char_3_loss: 0.0976 - Char_4_loss: 0.1178 - Char_5_loss: 0.1083 - Char_6_loss: 0.0347 - Char_1_accuracy: 0.9865 - Char_2_accuracy: 0.9734 - Char_3_accuracy: 0.9693 - Char_4_accuracy: 0.9606 - Char_5_accuracy: 0.9629 - Char_6_accuracy: 0.9915 - val_loss: 3.8341 - val_Char_1_loss: 0.3746 - val_Char_2_loss: 0.8239 - val_Char_3_loss: 0.7524 - val_Char_4_loss: 0.6596 - val_Char_5_loss: 0.7651 - val_Char_6_loss: 0.4584 - val_Char_1_accuracy: 0.8840 - val_Char_2_accuracy: 0.7960 - val_Char_3_accuracy: 0.8240 - val_Char_4_accuracy: 0.8500 - val_Char_5_accuracy: 0.8060 - val_Char_6_accuracy: 0.9000\n",
      "Epoch 9/50\n",
      "67/67 [==============================] - 34s 506ms/step - loss: 0.3612 - Char_1_loss: 0.0327 - Char_2_loss: 0.0642 - Char_3_loss: 0.0711 - Char_4_loss: 0.0822 - Char_5_loss: 0.0856 - Char_6_loss: 0.0255 - Char_1_accuracy: 0.9906 - Char_2_accuracy: 0.9811 - Char_3_accuracy: 0.9764 - Char_4_accuracy: 0.9728 - Char_5_accuracy: 0.9722 - Char_6_accuracy: 0.9945 - val_loss: 3.8672 - val_Char_1_loss: 0.4080 - val_Char_2_loss: 0.7308 - val_Char_3_loss: 0.7949 - val_Char_4_loss: 0.6166 - val_Char_5_loss: 0.8969 - val_Char_6_loss: 0.4201 - val_Char_1_accuracy: 0.8880 - val_Char_2_accuracy: 0.8340 - val_Char_3_accuracy: 0.8160 - val_Char_4_accuracy: 0.8500 - val_Char_5_accuracy: 0.8040 - val_Char_6_accuracy: 0.8880\n",
      "Epoch 10/50\n",
      "57/67 [========================>.....] - ETA: 5s - loss: 0.2895 - Char_1_loss: 0.0305 - Char_2_loss: 0.0523 - Char_3_loss: 0.0620 - Char_4_loss: 0.0645 - Char_5_loss: 0.0628 - Char_6_loss: 0.0175 - Char_1_accuracy: 0.9914 - Char_2_accuracy: 0.9849 - Char_3_accuracy: 0.9812 - Char_4_accuracy: 0.9785 - Char_5_accuracy: 0.9801 - Char_6_accuracy: 0.9970"
     ]
    }
   ],
   "source": [
    "batchsize = 128 # You may need to change this\n",
    "numbatches = math.ceil(numtrain / batchsize)\n",
    "\n",
    "checkpointfreq = 10 # Saves every this many epochs\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    \"myweights1\",\n",
    "    save_freq=numbatches * checkpointfreq,\n",
    "    save_weights_only=True)\n",
    "\n",
    "\n",
    "model.fit(train_images, [train_labels1, train_labels2, train_labels3,\n",
    "                        train_labels4, train_labels5, train_labels6],\n",
    "                        validation_data=(val_images, [\n",
    "                        val_labels1, val_labels2, val_labels3,\n",
    "                        val_labels4, val_labels5, val_labels6\n",
    "                        ]),\n",
    "                        batch_size=batchsize,\n",
    "                        epochs=50,\n",
    "                        callbacks=[model_checkpoint_callback])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save_weights('myweights1') \n",
    "#Use this to save weights.  Weights are saved after every 10 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7fa3306c0280>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.load_weights('myweights1')\n",
    "#Use this to load pre-trained weights or a checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below here, put your function for taking the output of the model on a given image and returning a string.  Pass an image to the function.\n",
    "\n",
    "For example, suppose we pass training image 0_vgxrub.jpeg to the model, and get an output of 6*21.  We pass this output to the function (along with the dictionary defined in the first cell), and it should return the string containing each of the six characters.  In this case, it would return VGXRUB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 14ms/step\n",
      "[5.8435871e-06 3.9144088e-06 4.2635801e-07 1.8845338e-06 2.2661762e-07\n",
      " 4.3168336e-07 9.9979156e-01 3.7835235e-07 2.2315431e-12 9.6192482e-05\n",
      " 2.0656225e-06 4.0300449e-07 5.7545538e-08 2.5928587e-06 3.1060892e-05\n",
      " 7.2568067e-09 4.5032943e-05 6.9336329e-07 8.7256342e-07 3.4650895e-07\n",
      " 1.6100599e-05]\n",
      "1.0000000937396814\n"
     ]
    }
   ],
   "source": [
    "# Example of how to pass a particular image to the model\n",
    "\n",
    "test1 = np.expand_dims(train_images[0],0)\n",
    "outtest1 = model.predict(test1)\n",
    "\n",
    "# The first character's output, for example, is \n",
    "\n",
    "print(outtest1[0][0])\n",
    "print(sum(outtest1[0][0]))\n",
    "\n",
    "# Look at which entry has the largest value (probability).  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Your function should go here:\n",
    "\n",
    "def ConvertOutput(output, dictionary):\n",
    "\n",
    "    string = \"\"\n",
    "    max_val = 0\n",
    "    for i in range(6):\n",
    "        for j in range(21):\n",
    "            if output[i][j]>max_val:\n",
    "                max_val = output[i][j]\n",
    "                index = j\n",
    "        string += dictionary[index]\n",
    "\n",
    "    return string\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below here is stuff for testing the model.  Don't run this code.  Leave it commented out for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"testfiles2 = os.listdir('./testdata/')\n",
    "testfiles = [f for f in testfiles2 if os.path.isfile('.' +'/testdata/' + f)]\n",
    "\n",
    "numtest = len(testfiles)\n",
    "\n",
    "test_images = np.zeros((numtest,250,50))\n",
    "test_labels = np.zeros((numtest,6,21))\n",
    "test_labels1 = np.zeros((numtest, 21))\n",
    "test_labels2 = np.zeros((numtest, 21))\n",
    "test_labels3 = np.zeros((numtest, 21))\n",
    "test_labels4 = np.zeros((numtest, 21))\n",
    "test_labels5 = np.zeros((numtest, 21))\n",
    "test_labels6 = np.zeros((numtest, 21))\n",
    "test_numlist = np.zeros((numtest))\n",
    "test_letters = ['     '] * numtest\n",
    "\n",
    "\n",
    "\n",
    "for i in range(numval):\n",
    "    img = Image.open('./testdata/' + testfiles[i]).convert('L')\n",
    "    data = np.transpose(np.asarray(img)) / 255\n",
    "    test_images[i] = data\n",
    "    test_numlist[i] = re.split(r\"[_.]\", testfiles[i])[0]\n",
    "    temp = re.split(r\"[_.]\", testfiles[i])\n",
    "    test_labels[i] = OneHotConverter(temp[1], dict2)\n",
    "    test_labels1[i] = test_labels[i][0]\n",
    "    test_labels2[i] = test_labels[i][1]\n",
    "    test_labels3[i] = test_labels[i][2]\n",
    "    test_labels4[i] = test_labels[i][3]\n",
    "    test_labels5[i] = test_labels[i][4]\n",
    "    test_labels6[i] = test_labels[i][5]\n",
    "    test_letters[i] = temp[1].upper()\n",
    "\n",
    "\n",
    "                   \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/safal/anaconda3/envs/tensorflow/lib/python3.11/site-packages/keras/utils/generic_utils.py:238: RuntimeWarning: divide by zero encountered in log10\n",
      "  numdigits = int(np.log10(self.target)) + 1\n"
     ]
    },
    {
     "ename": "OverflowError",
     "evalue": "cannot convert float infinity to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOverflowError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m results \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(test_images, [test_labels1, test_labels2, test_labels3,\n\u001b[1;32m      2\u001b[0m                         test_labels4, test_labels5, test_labels6])\n\u001b[1;32m      3\u001b[0m avgaccuracy \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28msum\u001b[39m(results[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m6\u001b[39m:])\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m6\u001b[39m \n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAverage character accuracy on test set: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavgaccuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m percent\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.11/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.11/site-packages/keras/utils/generic_utils.py:238\u001b[0m, in \u001b[0;36mProgbar.update\u001b[0;34m(self, current, values, finalize)\u001b[0m\n\u001b[1;32m    235\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 238\u001b[0m     numdigits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(np\u001b[38;5;241m.\u001b[39mlog10(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget)) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    239\u001b[0m     bar \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(numdigits) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124md/\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m [\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m%\u001b[39m (current, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget)\n\u001b[1;32m    240\u001b[0m     prog \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(current) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget\n",
      "\u001b[0;31mOverflowError\u001b[0m: cannot convert float infinity to integer"
     ]
    }
   ],
   "source": [
    "\"\"\" results = model.evaluate(test_images, [test_labels1, test_labels2, test_labels3,\n",
    "                        test_labels4, test_labels5, test_labels6])\n",
    "avgaccuracy = 100*sum(results[-6:])/6 \n",
    "\n",
    "\n",
    "print(f\"Average character accuracy on test set: {avgaccuracy:.2f} percent\") \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
